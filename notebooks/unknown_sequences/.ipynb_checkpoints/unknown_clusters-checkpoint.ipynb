{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unknowns greater than 120 amino acids \n",
    "\n",
    "Use only sequences greater than 120 amino acids - minimum for protein domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "#imports \n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from Bio import SeqIO\n",
    "from sklearn.cluster import KMeans\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.ticker as ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the sequences embedded with mini bacillus model \n",
    "embedding_bacter_s = pd.read_csv('../../embedded_sequences/bacillus_unknown_embedded.csv', sep = '\\t')\n",
    "embedding_bacter = embedding_bacter_s.dropna()\n",
    "embedding_bacter = embedding_bacter.sort_values(by=['Unnamed: 0'])\n",
    "bacter_keys = list(embedding_bacter['Unnamed: 0'].values)\n",
    "\n",
    "#standardise the embedding \n",
    "embedding_scaled = StandardScaler().fit_transform(embedding_bacter.drop(['Unnamed: 0'], axis = 1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elbow plot to determine the number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_sample = embedding_scaled[0:5000]\n",
    "\n",
    "Sum_of_squared_distances = []\n",
    "K = range(1,100)\n",
    "for k in K:\n",
    "    #print('K: ' + str(k))\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(embedding_sample)\n",
    "    Sum_of_squared_distances.append(km.inertia_)\n",
    "    \n",
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_squares = pd.DataFrame({\"k\": K,  'sum squares':Sum_of_squared_distances})\n",
    "sns.set(font_scale = 2)\n",
    "fig, ax = plt.subplots(1, 1, figsize = (15,10))\n",
    "sns.lineplot( data=sum_squares, x = 'k', y = 'sum squares', color = '#FFB944', linewidth = 8)\n",
    "ax.set_facecolor('white')\n",
    "plt.xlabel('Number of Clusters', fontsize = 20)\n",
    "plt.ylabel('Within Cluster Sum of Squares', fontsize = 20)\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(10))\n",
    "ax.xaxis.set_major_formatter(ticker.ScalarFormatter())\n",
    "ax.spines['left'].set_color('black')\n",
    "ax.spines['bottom'].set_color('black')\n",
    "plt.savefig(\"elbow.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise all the sequneces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmeans_model = KMeans(n_clusters=12, random_state=0)\n",
    "Kmeans_model.fit(embedding_scaled)\n",
    "Kmeans_labels = Kmeans_model.labels_ \n",
    "\n",
    "#do the tSNE\n",
    "tsne = TSNE(perplexity = 30, learning_rate =200)\n",
    "embedding_tsne = tsne.fit_transform(embedding_scaled)\n",
    "\n",
    "#colour by subclass \n",
    "tsne_df = pd.DataFrame(embedding_tsne, columns = ['dimension 1', 'dimension 2'])\n",
    "tsne_df.index = bacter_keys\n",
    "tsne_df['Kmeans'] = Kmeans_labels\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(x = 'dimension 1', y = 'dimension 2',hue = 'Kmeans', \n",
    "                \n",
    "                data = tsne_df, legend = 'full', s = 7,linewidth=0, alpha = 0.7, palette = 'tab20' )\n",
    "plt.legend([],[], frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.DataFrame({'md5': bacter_keys,'label': Kmeans_labels})\n",
    "ex = label_df[label_df['label'] == 4]['md5'].values\n",
    "\n",
    "embedding_scaled_df = pd.DataFrame(embedding_scaled, index = bacter_keys)\n",
    "ex_embedding = embedding_scaled_df.loc[ex]\n",
    "ex_embedding.values.var()\n",
    "\n",
    "#repeat this to get the variance within each of the clusters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(x = 'dimension 1', y = 'dimension 2', \n",
    "                \n",
    "                data = tsne_df, legend = 'full', s = 7,linewidth=0, alpha = 0.7, palette = 'tab20' )\n",
    "plt.legend([],[], frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x=range(1,len(per_var)+1), height=per_var, tick_label=labels)\n",
    "plt.ylabel('Percentage of Explained Variance')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.title('Scree Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do tSNE on the unknown sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmeans_model = KMeans(n_clusters=12, random_state=0)\n",
    "Kmeans_model.fit(embedding_scaled)\n",
    "Kmeans_labels = Kmeans_model.labels_ \n",
    "\n",
    "#do the tSNE\n",
    "tsne = TSNE(perplexity = 30, learning_rate =200)\n",
    "embedding_tsne = tsne.fit_transform(embedding_scaled)\n",
    "\n",
    "#colour by subclass \n",
    "tsne_df = pd.DataFrame(embedding_tsne, columns = ['dimension 1', 'dimension 2'])\n",
    "tsne_df.index = bacter_keys\n",
    "\n",
    "#set the number of clusters to be displayed \n",
    "k = 14\n",
    "\n",
    "Kmeans_model = KMeans(n_clusters=k, random_state=0)\n",
    "Kmeans_model.fit(embedding_scaled)\n",
    "Kmeans_labels = Kmeans_model.labels_ \n",
    "\n",
    "#get the kmeans centres\n",
    "Kmeans_centres = Kmeans_model.cluster_centers_\n",
    "\n",
    "# euclidean distance from each point to each cluster centroid\n",
    "D = cdist(embedding_scaled, Kmeans_centres, 'euclidean')\n",
    "\n",
    "centroid_list = []\n",
    "dist_list = [] \n",
    "\n",
    "for i in range(len(D)): \n",
    "    dist = np.min(D[i])\n",
    "    cent = np.where(D[i] == D[i].min())[0][0]\n",
    "    \n",
    "    #add distance and centroid information \n",
    "    dist_list.append(dist)\n",
    "    centroid_list.append(cent)\n",
    "    \n",
    "#assemble into a dataframe \n",
    "Kmeans_info = pd.DataFrame({'md5': bacter_keys, 'centroid': centroid_list, 'dist': dist_list})\n",
    "\n",
    "#get the 50 sequences closest to the centroid \n",
    "close_md5s = []\n",
    "close_centroids = []\n",
    "\n",
    "for i in range(0,k): \n",
    "    \n",
    "    #get a 'sub' dataframe corresponding to the centroid \n",
    "    this_centroid = Kmeans_info[Kmeans_info['centroid'] == i].sort_values('dist').reset_index()\n",
    "    \n",
    "    #get the top 100 md5 sums \n",
    "    this_md5 = this_centroid[0:100]['md5'].values\n",
    "    \n",
    "    #add these md5s to list\n",
    "    for md5 in this_md5: \n",
    "        close_md5s.append(md5)\n",
    "        close_centroids.append(i)\n",
    "        \n",
    "        \n",
    "close_md5_centroid = pd.DataFrame({'md5': close_md5s, 'centroid': close_centroids})\n",
    "close_md5_centroid = close_md5_centroid.sort_values('md5')\n",
    "\n",
    "embedding_close_tsnedf = tsne_df.loc[close_md5_centroid['md5']]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.scatterplot(x = 'dimension 1', y = 'dimension 2',hue = 'Kmeans', \n",
    "                \n",
    "                data = embedding_close_tsnedf, legend = 'full', s = 20,linewidth=0, alpha = 0.7, palette = 'tab20' )\n",
    "plt.legend([],[], frameon=False)\n",
    "plt.xlabel('Dimension 1', fontsize=18)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.ylabel('Dimension 2', fontsize=18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
